{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f59d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install datasets transformers soundfile librosa evaluate jiwer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa798782",
   "metadata": {},
   "source": [
    "## PARTE 1: IMPORT e CARICAMENTO del dataset LibriSpeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0645b768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento dataset LibriSpeech avvenuto!\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CTCLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from jiwer import wer, cer\n",
    "import time\n",
    "from torch.utils.data import Subset\n",
    "import random\n",
    "\n",
    "train_dataset = load_dataset(\"./local_dataset_loader\", name=\"local_dataset_loader\" ,split=\"train\", data_dir=\"./libriSpeech_data/LibriSpeech\", trust_remote_code=True)\n",
    "eval_dataset = load_dataset(\"./local_dataset_loader\", name=\"local_dataset_loader\", split=\"validation\", data_dir=\"./libriSpeech_data/LibriSpeech\", trust_remote_code=True)\n",
    "test_dataset = load_dataset(\"./local_dataset_loader\", name=\"local_dataset_loader\",split=\"test\", data_dir=\"./libriSpeech_data/LibriSpeech\", trust_remote_code=True)\n",
    "print(\"Caricamento dataset LibriSpeech avvenuto!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641dbcdc",
   "metadata": {},
   "source": [
    "## PARTE 2: VOCABOLARIO\n",
    "\n",
    "Serve a mappare ogni carattere (o token) a un indice numerico. Nel nostro caso, il modello trascrive caratteri (non parole), quindi il vocabolario è un char-level mapping \n",
    "{\"'\": 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26, '|': 27, '<blank>': 28, '<pad>': 29, '<unk>': 30}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2013f34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"'\": 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26, '|': 27, '<blank>': 28, '<pad>': 29, '<unk>': 30}\n"
     ]
    }
   ],
   "source": [
    "def build_vocab_dict(dataset):\n",
    "    all_text = \" \".join(dataset[\"text\"])\n",
    "    unique_chars = sorted(set(all_text) - {\" \"})\n",
    "    unique_chars.append(\"|\")\n",
    "\n",
    "    vocab_dict = {c: i for i, c in enumerate(unique_chars)}\n",
    "\n",
    "    vocab_dict[\"<blank>\"] = len(vocab_dict)\n",
    "    vocab_dict[\"<pad>\"] = len(vocab_dict) \n",
    "    vocab_dict[\"<unk>\"] = len(vocab_dict)\n",
    "\n",
    "    return vocab_dict\n",
    "\n",
    "vocab_dict = build_vocab_dict(train_dataset)\n",
    "print(vocab_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc418ed",
   "metadata": {},
   "source": [
    "## PARTE 3: PRE_PROCESSING\n",
    "\n",
    "### Conversione dell’audio in tensori numerici\n",
    "I modelli deep learning non possono lavorare direttamente con file audio o oggetti “audio”.\n",
    "\n",
    "### Tokenizzazione del testo\n",
    "Trasforma la trascrizione da testo in una sequenza di interi (labels), dove ogni carattere è mappato a un ID del vocabolario.\n",
    "È essenziale per usare la CTC Loss, che lavora su sequenze di ID e non stringhe di testo.\n",
    "\n",
    "### Dopo questo preprocessing abbiamo: \n",
    "\"input_values\" -> tensore audio normalizzato, pronto per essere passato a CNN/Transformer.\n",
    "\"labels\" -> lista di ID dei caratteri della trascrizione, per calcolare la CTC loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3da846c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avvio preprocessing ottimizzato..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1eb455b3a894bdbb563bac8662e549c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/28539 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9114f2b63cc441549c3b4f11afc9303a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/2703 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75ab21c3a9f4d528d02206df3a20185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/2620 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine preprocessing!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class SimpleProcessor:\n",
    "    def __init__(self, vocab_dict, target_sampling_rate=16000, augment=True):\n",
    "        self.vocab = vocab_dict\n",
    "        self.target_sr = target_sampling_rate\n",
    "        self.augment = augment\n",
    "\n",
    "    def preprocess_audio(self, audio_array, orig_sr):\n",
    "        if orig_sr != self.target_sr:\n",
    "            resampler = torchaudio.transforms.Resample(orig_sr, self.target_sr)\n",
    "            audio_array = resampler(torch.tensor(audio_array).float())\n",
    "        else:\n",
    "            audio_array = torch.tensor(audio_array).float()\n",
    "\n",
    "        if self.augment:\n",
    "            if random.random() < 0.5:\n",
    "                volume_factor = random.uniform(0.8, 1.2)\n",
    "                audio_array = audio_array * volume_factor\n",
    "\n",
    "            if random.random() < 0.3:\n",
    "                noise_factor = random.uniform(0.001, 0.01)\n",
    "                noise = torch.randn_like(audio_array) * noise_factor\n",
    "                audio_array = audio_array + noise\n",
    "\n",
    "        audio_array = (audio_array - audio_array.mean()) / (audio_array.std() + 1e-5)\n",
    "\n",
    "        return audio_array\n",
    "\n",
    "    def tokenize_text(self, text):\n",
    "        text = text.replace(\" \", \"|\")\n",
    "        return [self.vocab.get(c, self.vocab[\"<unk>\"]) for c in text]\n",
    "\n",
    "    def __call__(self, audio, sampling_rate, text=None):\n",
    "        inputs = self.preprocess_audio(audio, sampling_rate)\n",
    "\n",
    "        result = {\"input_values\": inputs}\n",
    "        if text is not None:\n",
    "            result[\"labels\"] = torch.tensor(self.tokenize_text(text), dtype=torch.long)\n",
    "        return result\n",
    "\n",
    "processor = SimpleProcessor(vocab_dict)\n",
    "\n",
    "def preprocess(batch):\n",
    "    audio = batch[\"audio\"][\"array\"]\n",
    "    sr = batch[\"audio\"][\"sampling_rate\"]\n",
    "    text = batch[\"text\"]\n",
    "\n",
    "    processed = processor(audio, sampling_rate=sr, text=text)\n",
    "    return {\n",
    "        \"input_values\": processed[\"input_values\"],\n",
    "        \"labels\": processed[\"labels\"]\n",
    "    }\n",
    "    \n",
    "print(\"Avvio preprocessing ottimizzato..\")\n",
    "\n",
    "train_dataset_processed = train_dataset.map(\n",
    "    preprocess,\n",
    "    remove_columns=train_dataset.column_names,\n",
    "    num_proc=4,\n",
    ")\n",
    "\n",
    "eval_dataset_processed = eval_dataset.map(\n",
    "    preprocess,\n",
    "    remove_columns=eval_dataset.column_names,\n",
    "    num_proc=4,\n",
    ")\n",
    "\n",
    "test_dataset_processed = test_dataset.map(\n",
    "    preprocess,\n",
    "    remove_columns=test_dataset.column_names,\n",
    "    num_proc=4,\n",
    ")\n",
    "\n",
    "print(\"Fine preprocessing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcaf38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_values', 'labels'])\n",
      "[-0.15206488966941833, -0.17493396997451782, 0.1320481300354004, 0.003173402277752757, -0.020163103938102722, 0.029104067012667656, -0.07104626297950745, 0.08140091598033905, -0.09795332700014114, 0.039900705218315125, -0.07659906148910522, 0.14178574085235596, -0.014021406881511211, 0.0908619835972786, -0.2531350553035736, 0.013963003642857075, -0.2295738309621811, 0.06235656514763832, 0.053652241826057434, 0.14166110754013062]\n",
      "[8, 1, 4, 27, 12, 1, 9, 4, 27, 2, 5, 6, 15, 18, 5, 27, 8, 5, 18, 27]\n",
      "[0.0007413655985146761, 0.0014564606826752424, 0.0021715557668358088, 0.0007413655985146761, 0.0007413655985146761, 0.0021715557668358088, 0.0021715557668358088, 0.0014564606826752424, 0.0014564606826752424, 0.0014564606826752424, 0.0014564606826752424, 0.0014564606826752424, 0.0014564606826752424, 0.0014564606826752424, 0.002886650850996375, 0.0021715557668358088, 0.0021715557668358088, 0.0021715557668358088, 0.0014564606826752424, 0.0014564606826752424]\n",
      "[19, 8, 15, 18, 20, 12, 25, 27, 1, 6, 20, 5, 18, 27, 16, 1, 19, 19, 9, 14]\n",
      "[-0.045244451612234116, -0.006274897139519453, 0.19141703844070435, 0.005515142343938351, -0.022698577493429184, 0.147803395986557, 0.05081850662827492, 0.1424807459115982, 0.07080940157175064, 0.1592939794063568, 0.05007239803671837, 0.23300844430923462, 0.06642192602157593, 0.1790512651205063, -0.059537164866924286, 0.10066285729408264, -0.01618179865181446, 0.28668490052223206, 0.1878446787595749, 0.23653635382652283]\n",
      "[25, 15, 21, 14, 7, 27, 6, 9, 20, 26, 15, 15, 20, 8, 27, 8, 1, 4, 27, 2]\n"
     ]
    }
   ],
   "source": [
    "#esempio per mostrare il preProcessing\n",
    "print(train_dataset_processed[0].keys())\n",
    "print(train_dataset_processed[0][\"input_values\"][:20])\n",
    "print(train_dataset_processed[0][\"labels\"][:20])\n",
    "\n",
    "print(eval_dataset_processed[0][\"input_values\"][:20])\n",
    "print(eval_dataset_processed[0][\"labels\"][:20])\n",
    "\n",
    "print(test_dataset_processed[0][\"input_values\"][:20])\n",
    "print(test_dataset_processed[0][\"labels\"][:20])\n",
    "\n",
    "# In base all'output accade che:\n",
    "\n",
    "# vocabolario: {\"'\": 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, \n",
    "#               'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26, '|': 27, '<pad>': 28, \n",
    "#               '<unk>': 29}\n",
    "\n",
    "# primi 20 caratteri del primo elemento: H A D   L A I D   B E F O R E\n",
    "# diventano: [H, A, D, '|', L, A, I, D, '|', B, E, F, O, R, E] -> [8, 1, 4, 27, 12, 1, 9, 4, 27, 2, 5, 6, 15, 18, 5] \n",
    "# label: [8, 1, 4, 27, 12, 1, 9, 4, 27, 2, 5, 6, 15, 18, 5, 27, ...]\n",
    "\n",
    "#lo stesso per l'eval e test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0feb9d",
   "metadata": {},
   "source": [
    "## PARTE 4: MODELLO\n",
    "\n",
    "1. Prende l’audio grezzo e lo trasforma in un’immagine chiamata spettrogramma Mel-log (una rappresentazione che mostra come l’energia del suono cambia nel tempo e nelle frequenze, più facile da interpretare per la rete)\n",
    "\n",
    "2. Passa questo spettrogramma a una CNN che estrae caratteristiche importanti e riduce la lunghezza della sequenza nel tempo riassumendo l’informazione utile.\n",
    " \n",
    "3. Le caratteristiche ottenute vengono date a un Transformer, che capisce le dipendenze temporali più complesse e le relazioni tra le parti della sequenza audio\n",
    "\n",
    "4. Un layer lineare trasforma queste informazioni in punteggi (logits) per ogni possibile carattere del vocabolario, cioè decide quali lettere o simboli sono più probabili in ogni momento.\n",
    "Questi punteggi vengono poi usati per calcolare la loss con la CTC e per generare il testo trascritto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9c2396",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimpleASRModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super(SimpleASRModel, self).__init__()\n",
    "\n",
    "        # 1. Trasformazione audio -> log-Mel spectrogram\n",
    "        self.melspec = T.MelSpectrogram(\n",
    "            sample_rate=16000,\n",
    "            n_fft=400,\n",
    "            hop_length=160,\n",
    "            n_mels=128\n",
    "        )\n",
    "        self.log_transform = lambda x: torch.log(x + 1e-5)\n",
    "\n",
    "        # 2. CNN per feature extraction (2 layer)\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(128, 256, kernel_size=5, stride=2, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, 256, kernel_size=5, stride=2, padding=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # 3. Transformer Encoder\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=256,\n",
    "                nhead=4,\n",
    "                dim_feedforward=512\n",
    "            ),\n",
    "            num_layers=3\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Linear(256, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch, audio_len) - waveform normalizzato\n",
    "        \"\"\"\n",
    "        x = self.melspec(x)\n",
    "        x = self.log_transform(x)\n",
    "\n",
    "        x = self.cnn(x)\n",
    "        x = x.permute(2, 0, 1)\n",
    "\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b713630f",
   "metadata": {},
   "source": [
    "## PARTE 5: COLLATE\n",
    "\n",
    "Funzione 'collate' per allineare tutto correttamente in un batch tensoriale. \n",
    "\n",
    "1. vengono estratte delle sequenze audio (input_values) e testo (labels):\n",
    "2. viene applicato il padding alle sequenze audio\n",
    "3. vengono calcolate le lunghezze originali delle sequenze audio prima del padding\n",
    "4. viene applicato il padding alle label testuali\n",
    "5. vengono calcolate le lunghezze reali delle label\n",
    "6. viene ritornato tutto in un unico dizionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252680cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    \n",
    "    inputs = [torch.tensor(item[\"input_values\"]) for item in batch]\n",
    "    targets = [torch.tensor(item[\"labels\"]) for item in batch]  \n",
    "    \n",
    "    inputs_padded = nn.utils.rnn.pad_sequence(inputs, batch_first=True)\n",
    "    \n",
    "    input_lengths = torch.tensor([len(i) for i in inputs])\n",
    "\n",
    "    targets_padded = nn.utils.rnn.pad_sequence(targets, batch_first=True, padding_value=vocab_dict[\"<pad>\"])\n",
    "\n",
    "    target_lengths = torch.tensor([len(t) for t in targets])\n",
    "        \n",
    "    return {\n",
    "        \"input_values\": inputs_padded, \n",
    "        \"labels\": targets_padded, \n",
    "        \"input_lengths\": input_lengths, \n",
    "        \"label_lengths\": target_lengths\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aec0fde",
   "metadata": {},
   "source": [
    "## PARTE 5: TRAIN LOOP\n",
    "\n",
    "1. Setup del dispositivo e inizializzazione del modello\n",
    "2. Preparazione dei dataloader -> usa solo i primi 1000 esempi per velocità.\n",
    "3. Decodifica 'greedy', utile per convertire le probabilità logaritmiche (output del modello) in una trascrizione testuale leggibile, scegliendo per ogni time step il carattere più probabile.\n",
    "4. Funzione 'compute' per calcolare la lunghezza temporale dopo la CNN. \n",
    "5. Training loop -> Abbiamo un audio (waveform) lungo input_lengths (in campioni, es. 16000 = 1 secondo).\n",
    "                    Lo trasformiamo in un mel-spectrogramma, cioè una sequenza di “frame” nel tempo.\n",
    "                    Passiamo quei frame nella CNN, che ha 2 layer con stride=2. La lunghezza la calcoliamo con compute\n",
    "                    Applica log_softmax perché la CTC loss richiede log-probabilità.\n",
    "\t                Flattening delle label rimuovendo padding\n",
    "                    Calcola la CTC loss\n",
    "\t                Backpropagation + aggiornamento pesi\n",
    "6. Valutazione sul dev set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8380a31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di batch per epoca: 250\n",
      "Epoch 1, Loss: 2.8777, Durata: 91.18s\n",
      "Epoch 1 - WER: 1.0000, CER: 0.9497\n",
      "\n",
      "Esempi di predizioni:\n",
      "Ref: SHORTLY AFTER PASSING ONE OF THESE CHAPELS WE CAME SUDDENLY UPON A VILLAGE WHICH STARTED UP OUT OF THE MIST AND I WAS ALARMED LEST I SHOULD BE MADE AN OBJECT OF CURIOSITY OR DISLIKE\n",
      "Pred: |A|A|T|A|IN|S|AN|A|A|A|E|E|A|R|A|E|N|A|R|\n",
      "Ref: MY GUIDES HOWEVER WERE WELL KNOWN AND THE NATURAL POLITENESS OF THE PEOPLE PREVENTED THEM FROM PUTTING ME TO ANY INCONVENIENCE BUT THEY COULD NOT HELP EYEING ME NOR I THEM\n",
      "Pred: |A|A|AT|R|R|R|AE|N|A|A|A|R|E|T|R|RE|R\n",
      "Ref: THE STREETS WERE NARROW AND UNPAVED BUT VERY FAIRLY CLEAN\n",
      "Pred: I|AR|R|A|\n",
      "--------------------------------------------------\n",
      "Epoch 2, Loss: 2.4514, Durata: 112.85s\n",
      "Epoch 2 - WER: 1.0000, CER: 0.7488\n",
      "\n",
      "Esempi di predizioni:\n",
      "Ref: SHORTLY AFTER PASSING ONE OF THESE CHAPELS WE CAME SUDDENLY UPON A VILLAGE WHICH STARTED UP OUT OF THE MIST AND I WAS ALARMED LEST I SHOULD BE MADE AN OBJECT OF CURIOSITY OR DISLIKE\n",
      "Pred: |O|R|T|TE|AT|IE|IE|TAT|OLS|E|E|EAD|E|ON|E|E|OE|TA|E|AE|NE|NE|EN|O|WNE|T|AT|TAE|E|E|E|T|IE|E|A|T|TE|E|WR|E|FO\n",
      "Ref: MY GUIDES HOWEVER WERE WELL KNOWN AND THE NATURAL POLITENESS OF THE PEOPLE PREVENTED THEM FROM PUTTING ME TO ANY INCONVENIENCE BUT THEY COULD NOT HELP EYEING ME NOR I THEM\n",
      "Pred: |AIE|IT|AT|E|WOE|W|EOER|AN|E|THO|L|ETOE|E|OL|ER|AN|E|ER|HE|WE|E|E|E|E|AITIE|OT|E|E|E|AR\n",
      "Ref: THE STREETS WERE NARROW AND UNPAVED BUT VERY FAIRLY CLEAN\n",
      "Pred: |IES|E|OE|R|A|N|ET|ERE|AE|A|IE|HE\n",
      "--------------------------------------------------\n",
      "Epoch 3, Loss: 2.2100, Durata: 115.87s\n",
      "Epoch 3 - WER: 1.0000, CER: 0.7404\n",
      "\n",
      "Esempi di predizioni:\n",
      "Ref: SHORTLY AFTER PASSING ONE OF THESE CHAPELS WE CAME SUDDENLY UPON A VILLAGE WHICH STARTED UP OUT OF THE MIST AND I WAS ALARMED LEST I SHOULD BE MADE AN OBJECT OF CURIOSITY OR DISLIKE\n",
      "Pred: |HO|T|TE|HAFHIN|I|E|TOT|OLS|E|HIND|FEAD|E|ON|ED|A|DOE|ADE|AT|ONER|N|I|AN|NO|O|OND|T|LOS|HA|HE|E|MNDE|OT|E|E|HA|ST|HE|E|WOR|O|FOIY\n",
      "Ref: MY GUIDES HOWEVER WERE WELL KNOWN AND THE NATURAL POLITENESS OF THE PEOPLE PREVENTED THEM FROM PUTTING ME TO ANY INCONVENIENCE BUT THEY COULD NOT HELP EYEING ME NOR I THEM\n",
      "Pred: |IN|T|HOATHO|WOE|O|O|R|AN|NACTHO|L|ETOE|HE|OL|OR|AN|E|ER|O|ORE|E|T|EN|I|E|HE|AITOE|OT|EN|E|I|N\n",
      "Ref: THE STREETS WERE NARROW AND UNPAVED BUT VERY FAIRLY CLEAN\n",
      "Pred: HIS|HE|E|RO|A|ON|P|ETDT|AOUD|HA|HAI|LE\n",
      "--------------------------------------------------\n",
      "Epoch 4, Loss: 2.0748, Durata: 113.33s\n",
      "Epoch 4 - WER: 1.0000, CER: 0.7253\n",
      "\n",
      "Esempi di predizioni:\n",
      "Ref: SHORTLY AFTER PASSING ONE OF THESE CHAPELS WE CAME SUDDENLY UPON A VILLAGE WHICH STARTED UP OUT OF THE MIST AND I WAS ALARMED LEST I SHOULD BE MADE AN OBJECT OF CURIOSITY OR DISLIKE\n",
      "Pred: |HO|E|T|TO|HAF|HIN|IE|TAT|POLS|E|HI|FEAD|E|ON|E|E|DOE|TINDED|A|HODE|N|AI|AN|IR|T|OSF|HESHE|E|MIDE|O|GI|OE|TA|OTHADE|ORDO|FI\n",
      "Ref: MY GUIDES HOWEVER WERE WELL KNOWN AND THE NATURAL POLITENESS OF THE PEOPLE PREVENTED THEM FROM PUTTING ME TO ANY INCONVENIENCE BUT THEY COULD NOT HELP EYEING ME NOR I THEM\n",
      "Pred: INDITHOUTHR|O|O|OAD|NACTHO|P|L|I|O|HE|BO|HR|AD|TORE|FO|WRE|TIR|E|E|HE|ATCOE|OT|I|AE|I|N\n",
      "Ref: THE STREETS WERE NARROW AND UNPAVED BUT VERY FAIRLY CLEAN\n",
      "Pred: HIS|HEH|E|RO|ION|PAE|T|BO|HA|HAI|LE\n",
      "--------------------------------------------------\n",
      "Epoch 5, Loss: 1.9776, Durata: 112.10s\n",
      "Epoch 5 - WER: 1.0000, CER: 0.7152\n",
      "\n",
      "Esempi di predizioni:\n",
      "Ref: SHORTLY AFTER PASSING ONE OF THESE CHAPELS WE CAME SUDDENLY UPON A VILLAGE WHICH STARTED UP OUT OF THE MIST AND I WAS ALARMED LEST I SHOULD BE MADE AN OBJECT OF CURIOSITY OR DISLIKE\n",
      "Pred: |HORO|E|AT|TH|HAF|FIN|IES|SOAT|OLS|E|HA|FEAE|E|ON|E|NO|DOE|SIN|E|A|HODO|NE|I|AN|AN|W|NRE|T|OSF|HEAT|HO|E|MINDE|NOT|GOE|O|HERE|OST|H|E|WOR|O|FIR|\n",
      "Ref: MY GUIDES HOWEVER WERE WELL KNOWN AND THE NATURAL POLITENESS OF THE PEOPLE PREVENTED THEM FROM PUTTING ME TO ANY INCONVENIENCE BUT THEY COULD NOT HELP EYEING ME NOR I THEM\n",
      "Pred: |IT|DIT|OTHER|W|O|O|O|W|OD|O|NATHO|L|I|OT|O|E|HE|OL|HOE|DEAN|E|FEO|WRE|E|R|AEN|HN|E|HE|HT|OE|OT|I|ME|N|IE|NAW\n",
      "Ref: THE STREETS WERE NARROW AND UNPAVED BUT VERY FAIRLY CLEAN\n",
      "Pred: HS|HE|RE|ARO|I|ON|PAN|E|TD|BO|HERT|HAE|LE|LH\n",
      "--------------------------------------------------\n",
      "Epoch 6, Loss: 1.9006, Durata: 114.87s\n",
      "Epoch 6 - WER: 1.0000, CER: 0.7034\n",
      "\n",
      "Esempi di predizioni:\n",
      "Ref: SHORTLY AFTER PASSING ONE OF THESE CHAPELS WE CAME SUDDENLY UPON A VILLAGE WHICH STARTED UP OUT OF THE MIST AND I WAS ALARMED LEST I SHOULD BE MADE AN OBJECT OF CURIOSITY OR DISLIKE\n",
      "Pred: SHORO|REAT|TH|HAF|FIN|IES|SAP|POLS|E|HA|FEAE|EY|PON|E|NE|DOESIN|E|A|HODO|NE|I|HN|AW|V|ONRE|T|OESF|FEASHO|BE|MYNDE|NOT|GIA|O|TREOSHADEY|ORYO|FOIR|\n",
      "Ref: MY GUIDES HOWEVER WERE WELL KNOWN AND THE NATURAL POLITENESS OF THE PEOPLE PREVENTED THEM FROM PUTTING ME TO ANY INCONVENIENCE BUT THEY COULD NOT HELP EYEING ME NOR I THEM\n",
      "Pred: |HIN|DIT|OUTER|WO|O|O|W|AON|OR|NACTHO|P|L|LI|ET|OE|HE|BOL|HR|DNAN|E|TOR|FE|WRY|E|FHR|AENG|HN|YEYE|HE|A|COE|HOT|I|MYE|N|OI|NAW\n",
      "Ref: THE STREETS WERE NARROW AND UNPAVED BUT VERY FAIRLY CLEAN\n",
      "Pred: |HSHES|RE|RO|I|ON|PAE|DT|BO|HART|HAY|LH\n",
      "--------------------------------------------------\n",
      "Epoch 7, Loss: 1.8360, Durata: 113.11s\n",
      "Epoch 7 - WER: 1.0000, CER: 0.7001\n",
      "\n",
      "Esempi di predizioni:\n",
      "Ref: SHORTLY AFTER PASSING ONE OF THESE CHAPELS WE CAME SUDDENLY UPON A VILLAGE WHICH STARTED UP OUT OF THE MIST AND I WAS ALARMED LEST I SHOULD BE MADE AN OBJECT OF CURIOSITY OR DISLIKE\n",
      "Pred: |HORO|E|ATH|HAS|FIE|WITES|SAT|POLSE|HA|FEAE|E|N|ED|NOI|TOES|TSIRE|AT|HATDOD|NE|IT|AN|I|O|V|MIR|T|OESFTFERTO|BE|MITE|AT|GIA|O|R|ATFOTE|WORDO|FOI\n",
      "Ref: MY GUIDES HOWEVER WERE WELL KNOWN AND THE NATURAL POLITENESS OF THE PEOPLE PREVENTED THEM FROM PUTTING ME TO ANY INCONVENIENCE BUT THEY COULD NOT HELP EYEING ME NOR I THEM\n",
      "Pred: |I|DIT|OUTHR|WO|O|OW|ANDOR|NATHO|PL|I|OT|OE|HE|POL|HR|DNAD|E|THRE|FE|ORE|ET|R|AEG|N|EYE|HA|AITCA|NHOT|IME|A|AI|NA\n",
      "Ref: THE STREETS WERE NARROW AND UNPAVED BUT VERY FAIRLY CLEAN\n",
      "Pred: HSHETH|RE|ARO|I|ON|PAO|TD|BOA|VEARET|ARI|LHE\n",
      "--------------------------------------------------\n",
      "Epoch 8, Loss: 1.7768, Durata: 117.18s\n",
      "Epoch 8 - WER: 1.0000, CER: 0.6969\n",
      "\n",
      "Esempi di predizioni:\n",
      "Ref: SHORTLY AFTER PASSING ONE OF THESE CHAPELS WE CAME SUDDENLY UPON A VILLAGE WHICH STARTED UP OUT OF THE MIST AND I WAS ALARMED LEST I SHOULD BE MADE AN OBJECT OF CURIOSITY OR DISLIKE\n",
      "Pred: |HOROLEAT|TH|HAF|FI|I|ES|SAP|PLS|E|HA|FEAE|LE|HON|E|NO|DOS|TAN|E|AT|HATDED|N|I|N|AW|WAR|T|LESF|FEAT|O|E|MATE|NAT|GIA|O|TREA|TFOTE|WRYO|FOI\n",
      "Ref: MY GUIDES HOWEVER WERE WELL KNOWN AND THE NATURAL POLITENESS OF THE PEOPLE PREVENTED THEM FROM PUTTING ME TO ANY INCONVENIENCE BUT THEY COULD NOT HELP EYEING ME NOR I THEM\n",
      "Pred: ID|DIT|HOUTHR|W|WO|NO|AN|ER|NACTHRA|PL|LIT|ET|OE|HE|BOL|HR|DNADER|THR|FER|WERYET|R|AN|N|NE|HE|AT|E|NHOT|AINM|N|AHI|N\n",
      "Ref: THE STREETS WERE NARROW AND UNPAVED BUT VERY FAIRLY CLEAN\n",
      "Pred: HSTET|RE|ARO|HI|ON|PAO|TD|HO|VERT|HAI|HE\n",
      "--------------------------------------------------\n",
      "Epoch 9, Loss: 1.7264, Durata: 113.26s\n",
      "Epoch 9 - WER: 1.0000, CER: 0.6952\n",
      "\n",
      "Esempi di predizioni:\n",
      "Ref: SHORTLY AFTER PASSING ONE OF THESE CHAPELS WE CAME SUDDENLY UPON A VILLAGE WHICH STARTED UP OUT OF THE MIST AND I WAS ALARMED LEST I SHOULD BE MADE AN OBJECT OF CURIOSITY OR DISLIKE\n",
      "Pred: |HORO|EATH|AS|I|I|ES|S|AT|PLS|E|HI|FEAD|LE|PON|NEI|TOES|TIN|ED|AT|HAT|O|NO|I|AN|AW|IR|T|OESFTFET|O|BE|MINDE|NAT|GIA|O|ERE|AF|THO|E|OR|O|FOIR\n",
      "Ref: MY GUIDES HOWEVER WERE WELL KNOWN AND THE NATURAL POLITENESS OF THE PEOPLE PREVENTED THEM FROM PUTTING ME TO ANY INCONVENIENCE BUT THEY COULD NOT HELP EYEING ME NOR I THEM\n",
      "Pred: I|DIT|OIUTHER|WO|O|O|AN|ER|NACHO|PL|IT|E|OE|E|POL|TOR|DEAN|THR|FEO|POERET|IR|AG|IN|ERHU|ATCA|NTHOT|IE|A|AI|A\n",
      "Ref: THE STREETS WERE NARROW AND UNPAVED BUT VERY FAIRLY CLEAN\n",
      "Pred: HS|HE|T|RE|ARO|HI|ON|AE|T|O|ERT|AI|HE\n",
      "--------------------------------------------------\n",
      "Epoch 10, Loss: 1.6767, Durata: 111.93s\n",
      "Epoch 10 - WER: 1.0000, CER: 0.6968\n",
      "\n",
      "Esempi di predizioni:\n",
      "Ref: SHORTLY AFTER PASSING ONE OF THESE CHAPELS WE CAME SUDDENLY UPON A VILLAGE WHICH STARTED UP OUT OF THE MIST AND I WAS ALARMED LEST I SHOULD BE MADE AN OBJECT OF CURIOSITY OR DISLIKE\n",
      "Pred: |HORO|REAT|TH|HAF|FI|WHI|ES|SOAT|PLS|E|HN|FELE|LH|ON|D|NO|DOES|TSARO|AP|HOU|O|NO|I|AN|AW|V|NR|T|OUSFTFEAS|O|BE|MINDE|OT|GIA|O|TREOF|TFO|E|WORDO|FIR\n",
      "Ref: MY GUIDES HOWEVER WERE WELL KNOWN AND THE NATURAL POLITENESS OF THE PEOPLE PREVENTED THEM FROM PUTTING ME TO ANY INCONVENIENCE BUT THEY COULD NOT HELP EYEING ME NOR I THEM\n",
      "Pred: |HID|DI|T|OUTHR|WO|LOU|NOWN|UN|OR|NACFHRO|PL|I|O|OE|TE|POLE|TR|D|ADE|THR|VO|POERE|TR|ANG|ION|YERS|HU|ATCO|NOHOT|I|ME|O|IR|AU\n",
      "Ref: THE STREETS WERE NARROW AND UNPAVED BUT VERY FAIRLY CLEAN\n",
      "Pred: |HSTE|SO|RE|RO|HI|ON|PAO|D|HO|VERT|HARIE|HEN\n",
      "--------------------------------------------------\n",
      "Epoch 11, Loss: 1.6332, Durata: 113.91s\n",
      "Epoch 11 - WER: 1.0000, CER: 0.6975\n",
      "\n",
      "Esempi di predizioni:\n",
      "Ref: SHORTLY AFTER PASSING ONE OF THESE CHAPELS WE CAME SUDDENLY UPON A VILLAGE WHICH STARTED UP OUT OF THE MIST AND I WAS ALARMED LEST I SHOULD BE MADE AN OBJECT OF CURIOSITY OR DISLIKE\n",
      "Pred: |HORO|E|AT|TH|AS|I|HI|ESOAT|POLS|E|H|FEAE|LE|N|N|TOES|SIN|E|AP|AT|O|NE|MI|IN|IWV|NR|T|OES|FESO|E|MINDE|OT|GIA|O|TR|ASF|E|WO|YO|FOI\n",
      "Ref: MY GUIDES HOWEVER WERE WELL KNOWN AND THE NATURAL POLITENESS OF THE PEOPLE PREVENTED THEM FROM PUTTING ME TO ANY INCONVENIENCE BUT THEY COULD NOT HELP EYEING ME NOR I THEM\n",
      "Pred: HI|DI|OUVER|WO|O|O|N|R|NACFHR|PLO|I|EOUT|TE|BOL|TR|TNAN|THRE|VRE|OERY|IRNANG|N|EHU|IT|U|NHOT|IN|M|I|NAU\n",
      "Ref: THE STREETS WERE NARROW AND UNPAVED BUT VERY FAIRLY CLEAN\n",
      "Pred: HSE|S|RE|RO|HI|ON|AO|T|O|VER|EI|LM\n",
      "--------------------------------------------------\n",
      "Epoch 12, Loss: 1.5894, Durata: 120.76s\n",
      "Epoch 12 - WER: 1.0000, CER: 0.6948\n",
      "\n",
      "Esempi di predizioni:\n",
      "Ref: SHORTLY AFTER PASSING ONE OF THESE CHAPELS WE CAME SUDDENLY UPON A VILLAGE WHICH STARTED UP OUT OF THE MIST AND I WAS ALARMED LEST I SHOULD BE MADE AN OBJECT OF CURIOSITY OR DISLIKE\n",
      "Pred: |H|ROLAT|TH|AS|I|HI|ESTSOAT|PLS|ECHA|FUAE|LHE|ON|NO|TOES|TAN|E|AT|HATNO|NE|MI|AN|AWV|NR|T|OUS|TPESUO|E|MINDE|AT|GIA|O|TRE|OSFO|E|WORYO|FOIG\n",
      "Ref: MY GUIDES HOWEVER WERE WELL KNOWN AND THE NATURAL POLITENESS OF THE PEOPLE PREVENTED THEM FROM PUTTING ME TO ANY INCONVENIENCE BUT THEY COULD NOT HELP EYEING ME NOR I THEM\n",
      "Pred: ID|DIT|OIUTER|WO|O|NO|AN|NATHRA|PL|LI|EOT|TE|BOL|TR|DNAN|THR|FOM|OERETRNAG|EN|YEHU|ATCIA|NHOT|HI|ME|IE|A\n",
      "Ref: THE STREETS WERE NARROW AND UNPAVED BUT VERY FAIRLY CLEAN\n",
      "Pred: HISTETS|RE|ARO|HI|ON|AO|O|VERE|AI|CLM\n",
      "--------------------------------------------------\n",
      "Epoch 13, Loss: 1.5449, Durata: 120.25s\n",
      "Epoch 13 - WER: 1.0000, CER: 0.6907\n",
      "\n",
      "Esempi di predizioni:\n",
      "Ref: SHORTLY AFTER PASSING ONE OF THESE CHAPELS WE CAME SUDDENLY UPON A VILLAGE WHICH STARTED UP OUT OF THE MIST AND I WAS ALARMED LEST I SHOULD BE MADE AN OBJECT OF CURIOSITY OR DISLIKE\n",
      "Pred: |HRO|AT|TE|HAF|FIN|WHI|ESTSAP|HOLS|E|HNFELE|LHE|PHN|NO|TOES|TSAR|AP|HATNO|NE|IT|AN|AW|V|ARG|T|OUSFTFEATO|E|MINTN|A|GIA|O|TR|OF|SFTHE|WO|DO|FOIR\n",
      "Ref: MY GUIDES HOWEVER WERE WELL KNOWN AND THE NATURAL POLITENESS OF THE PEOPLE PREVENTED THEM FROM PUTTING ME TO ANY INCONVENIENCE BUT THEY COULD NOT HELP EYEING ME NOR I THEM\n",
      "Pred: HIN|TITHOAOTER|WO|O|NO|NT|HUN|E|NA|HR|PL|I|EFOUE|THE|B|LETR|DNANE|THR|VR|HOERETRNANG|N|NEHT|ATCIA|NHOT|HINIE|ME|IE|NAU\n",
      "Ref: THE STREETS WERE NARROW AND UNPAVED BUT VERY FAIRLY CLEAN\n",
      "Pred: HIESTETES|RER|ARO|HIN|ON|HAR|TDT|OM|VARET|FARL|H|MN\n",
      "--------------------------------------------------\n",
      "Epoch 14, Loss: 1.5051, Durata: 120.30s\n",
      "Epoch 14 - WER: 1.0000, CER: 0.6941\n",
      "\n",
      "Esempi di predizioni:\n",
      "Ref: SHORTLY AFTER PASSING ONE OF THESE CHAPELS WE CAME SUDDENLY UPON A VILLAGE WHICH STARTED UP OUT OF THE MIST AND I WAS ALARMED LEST I SHOULD BE MADE AN OBJECT OF CURIOSITY OR DISLIKE\n",
      "Pred: SH|ROLAEAT|TE|ASF|EIN|WHI|ES|SAP|POLS|E|HN|FEAT|LH|PN|NO|TOS|SR|E|AT|AT|O|TO|MIT|AN|AW|V|WARNGT|OES|TPESO|E|MINTE|O|GIA|O|R|OFSFOH|WO|DOS|FOIG\n",
      "Ref: MY GUIDES HOWEVER WERE WELL KNOWN AND THE NATURAL POLITENESS OF THE PEOPLE PREVENTED THEM FROM PUTTING ME TO ANY INCONVENIENCE BUT THEY COULD NOT HELP EYEING ME NOR I THEM\n",
      "Pred: |I|TI|THOTER|WO|O|N|O|W|ONE|NA|HR|PWO|I|EFOTE|TE|B|LET|R|DHANE|THR|VO|OHREYET|RNAING|IN|YES|HU|ITCIA|NHOT|AINE|M|A|IE|AU\n",
      "Ref: THE STREETS WERE NARROW AND UNPAVED BUT VERY FAIRLY CLEAN\n",
      "Pred: HESHETS|R|ARO|HI|ON|AO|TD|OV|VERT|ERIE|LMIN\n",
      "--------------------------------------------------\n",
      "Epoch 15, Loss: 1.4618, Durata: 115.73s\n",
      "Epoch 15 - WER: 1.0000, CER: 0.6954\n",
      "\n",
      "Esempi di predizioni:\n",
      "Ref: SHORTLY AFTER PASSING ONE OF THESE CHAPELS WE CAME SUDDENLY UPON A VILLAGE WHICH STARTED UP OUT OF THE MIST AND I WAS ALARMED LEST I SHOULD BE MADE AN OBJECT OF CURIOSITY OR DISLIKE\n",
      "Pred: SHOROL|AOAT|TE|HAS|IN|WHI|EYESTSTOAP|POLS|OE|HN|HA|LH|PHN|NO|TOST|AR|AP|HATNO|OE|ISAN|HAOV|WAR|T|OUS|TPESTO|IE|MINDE|NAP|GOA|O|TR|OSFOHE|WORDO|FI\n",
      "Ref: MY GUIDES HOWEVER WERE WELL KNOWN AND THE NATURAL POLITENESS OF THE PEOPLE PREVENTED THEM FROM PUTTING ME TO ANY INCONVENIENCE BUT THEY COULD NOT HELP EYEING ME NOR I THEM\n",
      "Pred: |HID|TI|T|HOVER|WO|O|NO|UNEOR|NA|HRO|PW|I|EFOE|PE|BOLP|OR|DHANE|THR|VRM|HOHREYET|RNANG|ION|ESHU|ATCIO|NHOT|HIYE|MYE|IE|NA\n",
      "Ref: THE STREETS WERE NARROW AND UNPAVED BUT VERY FAIRLY CLEAN\n",
      "Pred: HISTETSU|R|ARO|I|ON|PAYO|T|O|VERE|I|CRLMN\n",
      "--------------------------------------------------\n",
      "Epoch 16, Loss: 1.4223, Durata: 119.17s\n",
      "Epoch 16 - WER: 1.0000, CER: 0.6944\n",
      "\n",
      "Esempi di predizioni:\n",
      "Ref: SHORTLY AFTER PASSING ONE OF THESE CHAPELS WE CAME SUDDENLY UPON A VILLAGE WHICH STARTED UP OUT OF THE MIST AND I WAS ALARMED LEST I SHOULD BE MADE AN OBJECT OF CURIOSITY OR DISLIKE\n",
      "Pred: SH|ROLAT|TE|AS|EIN|WHI|ESTSOAP|LS|OE|HNFHL|LH|PHON|NO|TOESARE|AT|HAT|O|TE|ISAN|HAWV|WARN|T|OUSFTPEASO|IE|MINDN|NAV|GOA|OTR|TOFSTFO|E|WO|DOE|FOI\n",
      "Ref: MY GUIDES HOWEVER WERE WELL KNOWN AND THE NATURAL POLITENESS OF THE PEOPLE PREVENTED THEM FROM PUTTING ME TO ANY INCONVENIENCE BUT THEY COULD NOT HELP EYEING ME NOR I THEM\n",
      "Pred: |HIA|DIV|THOTER|WO|WO|NO|W|ANER|NA|CHRO|PW|LI|EFOUE|TE|B|LE|TOR|DHANE|DHR|VOM|POHRET|H|RNANG|IN|TES|HU|IATCIA|NHOT|HIE|MYE|O|WA|IR|NAR\n",
      "Ref: THE STREETS WERE NARROW AND UNPAVED BUT VERY FAIRLY CLEAN\n",
      "Pred: |HIESTE|U|ER|AROL|I|ON|AO|D|OV|VEREHARH|RLMN\n",
      "--------------------------------------------------\n",
      "Epoch 17, Loss: 1.3844, Durata: 119.06s\n",
      "Epoch 17 - WER: 1.0000, CER: 0.7055\n",
      "\n",
      "Esempi di predizioni:\n",
      "Ref: SHORTLY AFTER PASSING ONE OF THESE CHAPELS WE CAME SUDDENLY UPON A VILLAGE WHICH STARTED UP OUT OF THE MIST AND I WAS ALARMED LEST I SHOULD BE MADE AN OBJECT OF CURIOSITY OR DISLIKE\n",
      "Pred: |H|ROLIA|AT|TE|AS|IN|WHI|ESTS|AP|PLSEOICH|FHL|LH|HN|NO|TOE|S|S|R|E|AT|AT|O|OE|I|AN|AW|ARN|T|OUS|TPEAS|O|IE|M|DE|A|TEA|O|R|OFSF|HE|WO|DO|FOIG\n",
      "Ref: MY GUIDES HOWEVER WERE WELL KNOWN AND THE NATURAL POLITENESS OF THE PEOPLE PREVENTED THEM FROM PUTTING ME TO ANY INCONVENIENCE BUT THEY COULD NOT HELP EYEING ME NOR I THEM\n",
      "Pred: HIA|DIV|T|O|ER|WO|O|N|O|W|HUNE|NA|HRO|PLWE|I|EFOT|PE|P|LEP|R|HU|E|HR|RM|POHREYT|H|RNAING|IN|EHU|IA|CIA|NHOT|HIE|MYA|A|IR|AU\n",
      "Ref: THE STREETS WERE NARROW AND UNPAVED BUT VERY FAIRLY CLEAN\n",
      "Pred: HIESTET|S|RE|ARO|IT|ON|AYO|TDT|OM|VERETFERY|LMIAN\n",
      "--------------------------------------------------\n",
      "Epoch 18, Loss: 1.3414, Durata: 119.52s\n",
      "Epoch 18 - WER: 1.0000, CER: 0.7029\n",
      "\n",
      "Esempi di predizioni:\n",
      "Ref: SHORTLY AFTER PASSING ONE OF THESE CHAPELS WE CAME SUDDENLY UPON A VILLAGE WHICH STARTED UP OUT OF THE MIST AND I WAS ALARMED LEST I SHOULD BE MADE AN OBJECT OF CURIOSITY OR DISLIKE\n",
      "Pred: S|OROLI|NATH|PAS|IN|WI|NESTS|AP|LS|OECHN|FU|LH|PHN|N|TOEST|AN|E|AT|ATNO|TE|IS|AN|AW|WAR|T|OUS|TPEASO|IE|MINDE|A|EA|OTR|OFSTFTHE|WOEDO|FOIH\n",
      "Ref: MY GUIDES HOWEVER WERE WELL KNOWN AND THE NATURAL POLITENESS OF THE PEOPLE PREVENTED THEM FROM PUTTING ME TO ANY INCONVENIENCE BUT THEY COULD NOT HELP EYEING ME NOR I THEM\n",
      "Pred: HIA|TNIV|T|O|OTER|W|O|WT|ANE|N|NAEFHRO|PHW|I|EF|OT|TE|B|LP|OR|DNUNE|THR|EM|F|OHRYENYET|H|RNIENG|ION|TESTHUT|IT|IA|NHOT|INYE|NYE|IR|AR\n",
      "Ref: THE STREETS WERE NARROW AND UNPAVED BUT VERY FAIRLY CLEAN\n",
      "Pred: HIESTETS|RER|RO|I|ON|PAO|TET|OV|VERET|FHECRLMN\n",
      "--------------------------------------------------\n",
      "Epoch 19, Loss: 1.3059, Durata: 115.60s\n",
      "Epoch 19 - WER: 1.0000, CER: 0.7065\n",
      "\n",
      "Esempi di predizioni:\n",
      "Ref: SHORTLY AFTER PASSING ONE OF THESE CHAPELS WE CAME SUDDENLY UPON A VILLAGE WHICH STARTED UP OUT OF THE MIST AND I WAS ALARMED LEST I SHOULD BE MADE AN OBJECT OF CURIOSITY OR DISLIKE\n",
      "Pred: |T|R|OL|AT|TH|TPAF|IN|WOI|NESTS|AP|LSEOE|H|EFEUT|H|PN|E|NO|ETORST|R|AT|AT|O|TE|I|AN|AN|ARN|OUS|TPESO|IE|M|TE|A|OA|O|R|OFSFO|E|WO|DOE|FOI|\n",
      "Ref: MY GUIDES HOWEVER WERE WELL KNOWN AND THE NATURAL POLITENESS OF THE PEOPLE PREVENTED THEM FROM PUTTING ME TO ANY INCONVENIENCE BUT THEY COULD NOT HELP EYEING ME NOR I THEM\n",
      "Pred: HIN|D|ET|O|O|ER|W|O|LO|R|AN|N|A|FORO|W|I|EFOUO|E|B|AEP|R|DNA|E|THR|O|OHRYEYT|RNANG|AN|E|EHU|IAT|IA|NHOT|HAIN|IE|MYE|A|IR|AR\n",
      "Ref: THE STREETS WERE NARROW AND UNPAVED BUT VERY FAIRLY CLEAN\n",
      "Pred: HIESTET|S|RE|NARO|AN|ONE|AYO|TE|HOV|VEARE|ARH|RMN\n",
      "--------------------------------------------------\n",
      "Epoch 20, Loss: 1.2674, Durata: 112.20s\n",
      "Epoch 20 - WER: 1.0000, CER: 0.7036\n",
      "\n",
      "Esempi di predizioni:\n",
      "Ref: SHORTLY AFTER PASSING ONE OF THESE CHAPELS WE CAME SUDDENLY UPON A VILLAGE WHICH STARTED UP OUT OF THE MIST AND I WAS ALARMED LEST I SHOULD BE MADE AN OBJECT OF CURIOSITY OR DISLIKE\n",
      "Pred: ST|ROL|AOATH|TAS|EIN|WHI|NEHESTS|APOLSLM|CH|FUAT|MH|PHN|EN|ETOS|T|AN|E|A|AT|O|TE|AI|AN|A|W|V|HAR|US|FEATE|IE|MINDN|A|HOA|OCRE|HOF|SF|HE|WO|DOE|FOIH\n",
      "Ref: MY GUIDES HOWEVER WERE WELL KNOWN AND THE NATURAL POLITENESS OF THE PEOPLE PREVENTED THEM FROM PUTTING ME TO ANY INCONVENIENCE BUT THEY COULD NOT HELP EYEING ME NOR I THEM\n",
      "Pred: HID|TNIV|T|HOTER|W|OE|AUNE|E|NA|HRO|PHW|I|EFOUE|TE|B|AEP|OR|D|A|E|THR|VRM|HRYENYT|H|ARNIYING|AN|TE|E|HUT|ATIE|N|HT|HIN|YE|MYE|A|IE|A\n",
      "Ref: THE STREETS WERE NARROW AND UNPAVED BUT VERY FAIRLY CLEAN\n",
      "Pred: HIESTET'S|RER|ARO|AN|ANE|AYO|TET|HOV|VERETFARH|CRLMN\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleASRModel(vocab_size=len(vocab_dict)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = CTCLoss(blank=vocab_dict[\"<blank>\"], zero_infinity=True)\n",
    "\n",
    "subset_indices = list(range(1000))\n",
    "small_dataset = Subset(train_dataset_processed, subset_indices)\n",
    "\n",
    "# per adesso ho commentato in quanto ci stiamo basando su un dataset molto più piccolo\n",
    "#train_loader = DataLoader(train_dataset_processed, batch_size=4, shuffle=True, collate_fn=collate)\n",
    "\n",
    "train_loader = DataLoader(small_dataset, batch_size=4, shuffle=True, collate_fn=collate)\n",
    "dev_loader = DataLoader(eval_dataset_processed, batch_size=4, shuffle=False, collate_fn=collate)\n",
    "\n",
    "print(\"Numero di batch per epoca:\", len(train_loader))\n",
    "\n",
    "def greedy_decode(log_probs, vocab_dict):\n",
    "    inv_vocab = {v: k for k, v in vocab_dict.items()}\n",
    "    pred_ids = torch.argmax(log_probs, dim=-1)\n",
    "    pred_texts = []\n",
    "\n",
    "    for b in range(pred_ids.shape[1]):\n",
    "        prev = None\n",
    "        sentence = []\n",
    "        for t in range(pred_ids.shape[0]):\n",
    "            idx = pred_ids[t, b].item()\n",
    "            if idx != prev and idx != vocab_dict[\"<blank>\"] and idx != vocab_dict[\"<pad>\"]:\n",
    "                if idx in inv_vocab:\n",
    "                    sentence.append(inv_vocab[idx])\n",
    "                prev = idx\n",
    "        pred_texts.append(\"\".join(sentence))\n",
    "    return pred_texts\n",
    "\n",
    "def compute_output_lengths(input_lengths, num_layers=2, stride=2):\n",
    "    for _ in range(num_layers):\n",
    "        input_lengths = (input_lengths + 1) // stride\n",
    "    return input_lengths\n",
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for batch in train_loader:\n",
    "        inputs = batch[\"input_values\"].to(device)\n",
    "        targets = batch[\"labels\"].to(device)\n",
    "        input_lengths = batch[\"input_lengths\"].to(device)\n",
    "        target_lengths = batch[\"label_lengths\"].to(device)\n",
    "\n",
    "        # mel_frame_length = ((input_len - n_fft) // hop_length) + 1\n",
    "        mel_frame_length = ((input_lengths - 400) // 160) + 1\n",
    "        adjusted_input_lengths = compute_output_lengths(mel_frame_length).to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        log_probs = nn.functional.log_softmax(outputs, dim=-1)\n",
    "        \n",
    "        flattened_targets = torch.cat([targets[i, :target_lengths[i]] for i in range(targets.size(0))])\n",
    "\n",
    "        loss = criterion(log_probs, flattened_targets, adjusted_input_lengths, target_lengths)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()        \n",
    "\n",
    "    duration = time.time() - start_time\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader):.4f}, Durata: {duration:.2f}s\")\n",
    "\n",
    "    model.eval()\n",
    "    all_preds, all_targets = [], []\n",
    "\n",
    "    # ======= VALUTAZIONE SU DEV ========\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dev_loader:\n",
    "            inputs = batch[\"input_values\"].to(device)\n",
    "            targets = batch[\"labels\"]\n",
    "            target_lengths = batch[\"label_lengths\"]\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            log_probs = nn.functional.log_softmax(outputs, dim=-1)\n",
    "\n",
    "            pred_texts = greedy_decode(log_probs.cpu(), vocab_dict)\n",
    "\n",
    "            inv_vocab = {v: k for k, v in vocab_dict.items()}\n",
    "            for i, length in enumerate(target_lengths):\n",
    "                target_ids = targets[i][:length].tolist()\n",
    "                target_text = \"\".join([inv_vocab[id] for id in target_ids])\n",
    "                target_text = target_text.replace(\"|\", \" \")\n",
    "                all_targets.append(target_text)\n",
    "\n",
    "            all_preds.extend(pred_texts)\n",
    "\n",
    "    wer_score = wer(all_targets, all_preds)\n",
    "    cer_score = cer(all_targets, all_preds)\n",
    "    print(f\"Epoch {epoch+1} - WER: {wer_score:.4f}, CER: {cer_score:.4f}\")\n",
    "\n",
    "    print(\"\\nEsempi di predizioni:\")\n",
    "    for i in range(min(3, len(all_preds))):\n",
    "        print(f\"Ref: {all_targets[i]}\")\n",
    "        print(f\"Pred: {all_preds[i]}\")\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
